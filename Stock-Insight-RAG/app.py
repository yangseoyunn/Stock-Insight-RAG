import os
import json
import streamlit as st
from datetime import datetime
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_classic.chains import RetrievalQA

# 1. API Key ì„¤ì •
os.environ["GROQ_API_KEY"] = "API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."

# 2. ì›¹ í˜ì´ì§€ UI ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Stock RAG Chatbot", page_icon="ğŸ“ˆ", layout="centered")
st.title("ğŸ“ˆ Stock-Insight-RAG")
st.caption("RLHF í”¼ë“œë°± ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•")


# 3. RAG ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• (í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ìºì‹±)
@st.cache_resource
def init_rag():
    loader = TextLoader("data/stock_kb.txt", encoding="utf-8")
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)
    texts = text_splitter.split_documents(documents)

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"},
    )

    vectorstore = FAISS.from_documents(texts, embeddings)

    llm = ChatGroq(model_name="llama-3.3-70b-versatile", temperature=0.1)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, retriever=vectorstore.as_retriever()
    )
    return qa_chain


qa_chain = init_rag()

# 4. ìƒíƒœ ì €ì¥ (ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í™”ë©´ì— ìœ ì§€í•˜ê¸° ìœ„í•¨)
if "current_qa" not in st.session_state:
    st.session_state.current_qa = None

# 5. ì‚¬ìš©ì ì±„íŒ… ì…ë ¥
prompt = st.chat_input(
    "ì£¼ì‹ íˆ¬ìì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”. (ex. ê¸ˆë¦¬ê°€ ì˜¤ë¥´ë©´ ê¸°ìˆ ì£¼ëŠ” ì–´ë–»ê²Œ ë¼?)"
)

if prompt:
    with st.spinner("ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        answer = qa_chain.run(prompt)
        st.session_state.current_qa = {"question": prompt, "answer": answer}

# 6. ê²°ê³¼ ì¶œë ¥ ë° RLHF í”¼ë“œë°± í¼ (ë‹µë³€ì´ ìƒì„±ë˜ì—ˆì„ ë•Œë§Œ í‘œì‹œ)
if st.session_state.current_qa:
    st.chat_message("user").write(st.session_state.current_qa["question"])
    st.chat_message("assistant").write(st.session_state.current_qa["answer"])

    st.divider()
    st.subheader("ğŸ“ RLHF ë³´ìƒ ë°ì´í„° ìˆ˜ì§‘ (Human Feedback)")

    with st.form(key="feedback-form", clear_on_submit=True):
        st.write(
            "ìƒì„±ëœ ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°±ì„ ë‚¨ê²¨ ì£¼ì„¸ìš”. (ëª¨ë¸ ê°œì„ ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤!)"
        )
        score = st.slider("Reworad Score(1 : ë§¤ìš° ë‚˜ì¨ ~ 5: ë§¤ìš° ì¢‹ìŒ)", 1, 5, 3)
        reason = st.text_input("í”¼ë“œë°± ì´ìœ  (ì„ íƒ ì‚¬í•­)")
        submit_btn = st.form_submit_button("ë°ì´í„°ì…‹ì— ì €ì¥")

        if submit_btn:
            # í‰ê°€ ë°ì´í„°ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
            log_data = {
                "timestamp": str(datetime.now()),
                "prompt": st.session_state.current_qa["question"],
                "response": st.session_state.current_qa["answer"],
                "reward_score": score,
                "feedback_reason": reason,
            }
            with open("dataset/feedback.jsonl", "a", encoding="utf-8") as f:
                f.write(json.dumps(log_data) + "\n")

            st.success(
                "í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë„ì›€ì„ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Š (`dataset/feedback.jsonl`)"
            )
            st.session_state.current_qa = None  # ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™”


